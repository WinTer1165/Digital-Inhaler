{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ac4e4d",
   "metadata": {},
   "source": [
    "# Asthma Diagnosis with a 1‑bit (BNN) Classifier\n",
    "\n",
    "This notebook loads the provided dataset, removes unnecessary columns, and trains a compact **Binarized Neural Network (BNN)** to predict whether a patient is asthmatic (`Diagnosis` = 1) or not (`Diagnosis` = 0).\n",
    "\n",
    "**Pipeline overview**\n",
    "1. Load data from `asthma_disease_data.csv`\n",
    "2. Clean & feature select (drop identifiers, non‑predictive columns, near‑constant columns)\n",
    "3. Standardize numeric features\n",
    "4. Train a small fully‑connected BNN (binarized weights & activations)\n",
    "5. Evaluate (accuracy, F1, ROC‑AUC, confusion matrix)\n",
    "6. Export a lightweight artifact for deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6817001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2392, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>SleepQuality</th>\n",
       "      <th>...</th>\n",
       "      <th>LungFunctionFEV1</th>\n",
       "      <th>LungFunctionFVC</th>\n",
       "      <th>Wheezing</th>\n",
       "      <th>ShortnessOfBreath</th>\n",
       "      <th>ChestTightness</th>\n",
       "      <th>Coughing</th>\n",
       "      <th>NighttimeSymptoms</th>\n",
       "      <th>ExerciseInduced</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>DoctorInCharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5034</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.848744</td>\n",
       "      <td>0</td>\n",
       "      <td>0.894448</td>\n",
       "      <td>5.488696</td>\n",
       "      <td>8.701003</td>\n",
       "      <td>...</td>\n",
       "      <td>1.369051</td>\n",
       "      <td>4.941206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Dr_Confid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5035</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22.757042</td>\n",
       "      <td>0</td>\n",
       "      <td>5.897329</td>\n",
       "      <td>6.341014</td>\n",
       "      <td>5.153966</td>\n",
       "      <td>...</td>\n",
       "      <td>2.197767</td>\n",
       "      <td>1.702393</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Dr_Confid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5036</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18.395396</td>\n",
       "      <td>0</td>\n",
       "      <td>6.739367</td>\n",
       "      <td>9.196237</td>\n",
       "      <td>6.840647</td>\n",
       "      <td>...</td>\n",
       "      <td>1.698011</td>\n",
       "      <td>5.022553</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Dr_Confid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  Age  Gender  Ethnicity  EducationLevel        BMI  Smoking  \\\n",
       "0       5034   63       0          1               0  15.848744        0   \n",
       "1       5035   26       1          2               2  22.757042        0   \n",
       "2       5036   57       0          2               1  18.395396        0   \n",
       "\n",
       "   PhysicalActivity  DietQuality  SleepQuality  ...  LungFunctionFEV1  \\\n",
       "0          0.894448     5.488696      8.701003  ...          1.369051   \n",
       "1          5.897329     6.341014      5.153966  ...          2.197767   \n",
       "2          6.739367     9.196237      6.840647  ...          1.698011   \n",
       "\n",
       "   LungFunctionFVC  Wheezing  ShortnessOfBreath  ChestTightness  Coughing  \\\n",
       "0         4.941206         0                  0               1         0   \n",
       "1         1.702393         1                  0               0         1   \n",
       "2         5.022553         1                  1               1         0   \n",
       "\n",
       "   NighttimeSymptoms  ExerciseInduced  Diagnosis  DoctorInCharge  \n",
       "0                  0                1          0       Dr_Confid  \n",
       "1                  1                1          0       Dr_Confid  \n",
       "2                  1                1          0       Dr_Confid  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === Setup ===\n",
    "import os, math, json, random, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "CSV_PATH = Path('asthma_disease_data.csv')  # update if needed\n",
    "\n",
    "assert CSV_PATH.exists(), f\"CSV not found: {CSV_PATH}\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a52972",
   "metadata": {},
   "source": [
    "## 1) Clean & Feature Selection\n",
    "\n",
    "Rules:\n",
    "- Drop obvious identifiers / leakage: `PatientID`, `DoctorInCharge` (object/string), but keep `Diagnosis` as target\n",
    "- Auto‑drop columns with (a) >95% same value (near‑constant), (b) all‑null, or (c) duplicate columns\n",
    "- Keep only numeric predictors; coerce booleans/ints/floats; leave target untouched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f7c714e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['DoctorInCharge', 'PatientID']\n",
      "Remaining predictors: 26\n",
      "Target: Diagnosis\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>SleepQuality</th>\n",
       "      <th>PollutionExposure</th>\n",
       "      <th>...</th>\n",
       "      <th>GastroesophagealReflux</th>\n",
       "      <th>LungFunctionFEV1</th>\n",
       "      <th>LungFunctionFVC</th>\n",
       "      <th>Wheezing</th>\n",
       "      <th>ShortnessOfBreath</th>\n",
       "      <th>ChestTightness</th>\n",
       "      <th>Coughing</th>\n",
       "      <th>NighttimeSymptoms</th>\n",
       "      <th>ExerciseInduced</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.848744</td>\n",
       "      <td>0</td>\n",
       "      <td>0.894448</td>\n",
       "      <td>5.488696</td>\n",
       "      <td>8.701003</td>\n",
       "      <td>7.388481</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.369051</td>\n",
       "      <td>4.941206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22.757042</td>\n",
       "      <td>0</td>\n",
       "      <td>5.897329</td>\n",
       "      <td>6.341014</td>\n",
       "      <td>5.153966</td>\n",
       "      <td>1.969838</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.197767</td>\n",
       "      <td>1.702393</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18.395396</td>\n",
       "      <td>0</td>\n",
       "      <td>6.739367</td>\n",
       "      <td>9.196237</td>\n",
       "      <td>6.840647</td>\n",
       "      <td>1.460593</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.698011</td>\n",
       "      <td>5.022553</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Ethnicity  EducationLevel        BMI  Smoking  \\\n",
       "0   63       0          1               0  15.848744        0   \n",
       "1   26       1          2               2  22.757042        0   \n",
       "2   57       0          2               1  18.395396        0   \n",
       "\n",
       "   PhysicalActivity  DietQuality  SleepQuality  PollutionExposure  ...  \\\n",
       "0          0.894448     5.488696      8.701003           7.388481  ...   \n",
       "1          5.897329     6.341014      5.153966           1.969838  ...   \n",
       "2          6.739367     9.196237      6.840647           1.460593  ...   \n",
       "\n",
       "   GastroesophagealReflux  LungFunctionFEV1  LungFunctionFVC  Wheezing  \\\n",
       "0                       0          1.369051         4.941206         0   \n",
       "1                       0          2.197767         1.702393         1   \n",
       "2                       0          1.698011         5.022553         1   \n",
       "\n",
       "   ShortnessOfBreath  ChestTightness  Coughing  NighttimeSymptoms  \\\n",
       "0                  0               1         0                  0   \n",
       "1                  0               0         1                  1   \n",
       "2                  1               1         0                  1   \n",
       "\n",
       "   ExerciseInduced  Diagnosis  \n",
       "0                1          0  \n",
       "1                1          0  \n",
       "2                1          0  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "TARGET_CANDIDATES = ['Diagnosis', 'asthma', 'Asthma', 'is_asthmatic']\n",
    "target_col = None\n",
    "for c in TARGET_CANDIDATES:\n",
    "    if c in df.columns:\n",
    "        target_col = c\n",
    "        break\n",
    "assert target_col is not None, f\"Target column not found; looked for {TARGET_CANDIDATES}\"\n",
    "\n",
    "# Identify identifier-like columns to drop (besides target)\n",
    "id_like = []\n",
    "for c in df.columns:\n",
    "    if c == target_col: \n",
    "        continue\n",
    "    if c.lower() in ['patientid','id','uuid','guid','recordid','doctorincharge','Ethnicity']:\n",
    "        id_like.append(c)\n",
    "    # Heuristic: object dtype that's not small categorical could be free text -> drop\n",
    "    if df[c].dtype == 'object':\n",
    "        nunique = df[c].nunique(dropna=True)\n",
    "        if nunique > 20:\n",
    "            id_like.append(c)\n",
    "\n",
    "id_like = sorted(set(id_like))\n",
    "\n",
    "# Remove all-null, near-constant, and duplicates\n",
    "drop_cols = set(id_like)\n",
    "for c in df.columns:\n",
    "    if c == target_col: \n",
    "        continue\n",
    "    s = df[c]\n",
    "    if s.isna().all():\n",
    "        drop_cols.add(c)\n",
    "    else:\n",
    "        # near-constant\n",
    "        top_freq = s.value_counts(dropna=False).iloc[0] / len(s)\n",
    "        if top_freq > 0.95:\n",
    "            drop_cols.add(c)\n",
    "\n",
    "# drop duplicate columns by values hash (excluding target)\n",
    "seen = {}\n",
    "for c in df.columns:\n",
    "    if c == target_col or c in drop_cols: \n",
    "        continue\n",
    "    key = tuple(pd.util.hash_pandas_object(df[c].fillna('__NA__')).values)\n",
    "    if key in seen:\n",
    "        drop_cols.add(c)\n",
    "    else:\n",
    "        seen[key] = c\n",
    "\n",
    "df_clean = df.drop(columns=list(drop_cols), errors='ignore').copy()\n",
    "\n",
    "# Keep only numeric predictors (int, float, bool)\n",
    "predictors = [c for c in df_clean.columns if c != target_col]\n",
    "non_numeric = [c for c in predictors if not pd.api.types.is_numeric_dtype(df_clean[c])]\n",
    "df_clean = df_clean.drop(columns=non_numeric, errors='ignore')\n",
    "predictors = [c for c in df_clean.columns if c != target_col]\n",
    "\n",
    "print(\"Dropped columns:\", sorted(drop_cols | set(non_numeric)))\n",
    "print(\"Remaining predictors:\", len(predictors))\n",
    "print(\"Target:\", target_col)\n",
    "df_clean.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3793da4c",
   "metadata": {},
   "source": [
    "## 2) Train / Test Split + Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d51467c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2152, 26), (240, 26))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ensure target is binary 0/1\n",
    "y_raw = df_clean[target_col].astype(int).values\n",
    "assert set(np.unique(y_raw)).issubset({0,1}), \"Target must be binary 0/1.\"\n",
    "\n",
    "X = df_clean[predictors].astype(np.float32).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_raw, test_size=0.1, random_state=SEED, stratify=y_raw\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_test  = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "x_mean = scaler.mean_.astype(np.float32)\n",
    "x_scale = scaler.scale_.astype(np.float32)\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7c2fdd",
   "metadata": {},
   "source": [
    "## 3) Define a Simple Fully‑Connected BNN\n",
    "\n",
    "We binarize weights & activations to {−1, +1} during the forward pass (keep float32 shadows for updates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5105b30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "class SignBinarize(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        return x.sign()\n",
    "    @staticmethod\n",
    "    def backward(ctx, g):\n",
    "        # Straight-through estimator (clipped)\n",
    "        return g.clamp_(-1, 1)\n",
    "\n",
    "def binarize(x):\n",
    "    return SignBinarize.apply(x)\n",
    "\n",
    "class BinaryLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        nn.init.kaiming_normal_(self.weight, nonlinearity='relu')\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features)) if bias else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        w_bin = binarize(self.weight)\n",
    "        x_bin = binarize(x)\n",
    "        out = F.linear(x_bin, w_bin, self.bias)\n",
    "        return out\n",
    "\n",
    "class BNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=[128, 64], p_drop=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = BinaryLinear(in_dim, hidden[0])\n",
    "        self.bn1 = nn.BatchNorm1d(hidden[0])\n",
    "        self.fc2 = BinaryLinear(hidden[0], hidden[1])\n",
    "        self.bn2 = nn.BatchNorm1d(hidden[1])\n",
    "        self.out = BinaryLinear(hidden[1], 1)\n",
    "        self.dropout = nn.Dropout(p_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x); x = self.bn1(x); x = F.hardtanh(x); x = self.dropout(x)\n",
    "        x = self.fc2(x); x = self.bn2(x); x = F.hardtanh(x); x = self.dropout(x)\n",
    "        logit = self.out(x)  # binary logit\n",
    "        return logit.squeeze(1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e9f37",
   "metadata": {},
   "source": [
    "## 4) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "547ebf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "Xtr = torch.from_numpy(X_train).to(device)\n",
    "ytr = torch.from_numpy(y_train.astype(np.float32)).to(device)\n",
    "Xte = torch.from_numpy(X_test).to(device)\n",
    "yte = torch.from_numpy(y_test.astype(np.float32)).to(device)\n",
    "\n",
    "train_ds = TensorDataset(Xtr, ytr)\n",
    "test_ds  = TensorDataset(Xte, yte)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=2000, shuffle=True, drop_last=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=512, shuffle=False, drop_last=False)\n",
    "\n",
    "model = BNN(in_dim=X_train.shape[1]).to(device)\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss, n = 0.0, 0\n",
    "    all_logits, all_y = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            logits = model(xb)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "            n += xb.size(0)\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_y.append(yb.cpu())\n",
    "    logits = torch.cat(all_logits).numpy()\n",
    "    y_true = torch.cat(all_y).numpy()\n",
    "    y_prob = 1/(1+np.exp(-logits))\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "    except:\n",
    "        auc = float('nan')\n",
    "    return total_loss/n, acc, f1, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b34d740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | val_loss=1.9330 acc=0.708 f1=0.079 auc=0.607\n",
      "Epoch 05 | val_loss=2.2015 acc=0.658 f1=0.089 auc=0.548\n",
      "Epoch 10 | val_loss=2.4648 acc=0.588 f1=0.075 auc=0.544\n",
      "Epoch 15 | val_loss=1.9680 acc=0.658 f1=0.109 auc=0.637\n",
      "Epoch 20 | val_loss=1.9681 acc=0.654 f1=0.144 auc=0.669\n",
      "Epoch 25 | val_loss=2.0635 acc=0.629 f1=0.101 auc=0.615\n",
      "Epoch 30 | val_loss=2.1009 acc=0.646 f1=0.124 auc=0.643\n",
      "Epoch 35 | val_loss=2.0393 acc=0.617 f1=0.115 auc=0.663\n",
      "Epoch 40 | val_loss=1.7265 acc=0.646 f1=0.141 auc=0.660\n",
      "Epoch 45 | val_loss=1.7804 acc=0.654 f1=0.144 auc=0.664\n",
      "Epoch 50 | val_loss=1.3975 acc=0.667 f1=0.130 auc=0.682\n",
      "Epoch 55 | val_loss=1.6535 acc=0.667 f1=0.130 auc=0.638\n",
      "Epoch 60 | val_loss=1.6126 acc=0.700 f1=0.122 auc=0.546\n",
      "Epoch 65 | val_loss=1.4118 acc=0.683 f1=0.156 auc=0.686\n",
      "Epoch 70 | val_loss=1.9414 acc=0.617 f1=0.061 auc=0.495\n",
      "Epoch 75 | val_loss=1.3550 acc=0.696 f1=0.052 auc=0.577\n",
      "Epoch 80 | val_loss=1.3996 acc=0.704 f1=0.145 auc=0.647\n",
      "Epoch 85 | val_loss=1.7748 acc=0.671 f1=0.151 auc=0.622\n",
      "Epoch 90 | val_loss=1.4338 acc=0.725 f1=0.132 auc=0.610\n",
      "Epoch 95 | val_loss=1.4448 acc=0.704 f1=0.123 auc=0.573\n",
      "Epoch 100 | val_loss=1.2815 acc=0.713 f1=0.104 auc=0.610\n",
      "Epoch 105 | val_loss=1.4845 acc=0.683 f1=0.156 auc=0.606\n",
      "Epoch 110 | val_loss=1.1754 acc=0.742 f1=0.088 auc=0.543\n",
      "Epoch 115 | val_loss=1.2480 acc=0.733 f1=0.111 auc=0.598\n",
      "Epoch 120 | val_loss=1.4200 acc=0.729 f1=0.133 auc=0.620\n",
      "Epoch 125 | val_loss=1.1770 acc=0.725 f1=0.132 auc=0.588\n",
      "Epoch 130 | val_loss=1.3834 acc=0.704 f1=0.078 auc=0.470\n",
      "Epoch 135 | val_loss=1.0935 acc=0.750 f1=0.062 auc=0.574\n",
      "Epoch 140 | val_loss=1.2183 acc=0.725 f1=0.083 auc=0.573\n",
      "Epoch 145 | val_loss=1.2442 acc=0.717 f1=0.128 auc=0.611\n",
      "Epoch 150 | val_loss=1.3384 acc=0.696 f1=0.076 auc=0.542\n",
      "Epoch 155 | val_loss=1.1061 acc=0.733 f1=0.086 auc=0.558\n",
      "Epoch 160 | val_loss=0.9654 acc=0.771 f1=0.154 auc=0.689\n",
      "Epoch 165 | val_loss=1.1922 acc=0.746 f1=0.116 auc=0.644\n",
      "Epoch 170 | val_loss=1.0747 acc=0.767 f1=0.125 auc=0.603\n",
      "Epoch 175 | val_loss=1.1209 acc=0.758 f1=0.147 auc=0.605\n",
      "Epoch 180 | val_loss=1.4530 acc=0.704 f1=0.123 auc=0.554\n",
      "Epoch 185 | val_loss=1.1867 acc=0.717 f1=0.150 auc=0.664\n",
      "Epoch 190 | val_loss=1.2261 acc=0.708 f1=0.125 auc=0.614\n",
      "Epoch 195 | val_loss=1.1421 acc=0.750 f1=0.118 auc=0.630\n",
      "Epoch 200 | val_loss=1.3285 acc=0.713 f1=0.055 auc=0.514\n",
      "Epoch 205 | val_loss=1.1547 acc=0.750 f1=0.118 auc=0.560\n",
      "Epoch 210 | val_loss=1.0328 acc=0.783 f1=0.133 auc=0.603\n",
      "Epoch 215 | val_loss=1.0561 acc=0.754 f1=0.063 auc=0.595\n",
      "Epoch 220 | val_loss=1.0416 acc=0.738 f1=0.113 auc=0.625\n",
      "Epoch 225 | val_loss=1.0275 acc=0.800 f1=0.143 auc=0.625\n",
      "Epoch 230 | val_loss=1.5129 acc=0.692 f1=0.098 auc=0.542\n",
      "Epoch 235 | val_loss=1.4968 acc=0.725 f1=0.108 auc=0.548\n",
      "Epoch 240 | val_loss=1.1976 acc=0.762 f1=0.149 auc=0.656\n",
      "Epoch 245 | val_loss=1.0865 acc=0.758 f1=0.033 auc=0.571\n",
      "Epoch 250 | val_loss=0.8774 acc=0.783 f1=0.103 auc=0.607\n",
      "Epoch 255 | val_loss=0.8525 acc=0.808 f1=0.080 auc=0.582\n",
      "Epoch 260 | val_loss=0.9795 acc=0.779 f1=0.070 auc=0.485\n",
      "Epoch 265 | val_loss=1.3396 acc=0.738 f1=0.087 auc=0.555\n",
      "Epoch 270 | val_loss=1.0819 acc=0.804 f1=0.145 auc=0.598\n",
      "Epoch 275 | val_loss=0.9346 acc=0.783 f1=0.133 auc=0.598\n",
      "Epoch 280 | val_loss=1.0865 acc=0.775 f1=0.100 auc=0.553\n",
      "Epoch 285 | val_loss=1.0575 acc=0.754 f1=0.092 auc=0.548\n",
      "Epoch 290 | val_loss=0.8571 acc=0.821 f1=0.189 auc=0.564\n",
      "Epoch 295 | val_loss=1.2249 acc=0.767 f1=0.067 auc=0.495\n",
      "Epoch 300 | val_loss=0.8723 acc=0.792 f1=0.107 auc=0.613\n",
      "Epoch 305 | val_loss=0.9980 acc=0.767 f1=0.125 auc=0.577\n",
      "Epoch 310 | val_loss=1.0157 acc=0.796 f1=0.075 auc=0.449\n",
      "Epoch 315 | val_loss=1.1817 acc=0.758 f1=0.065 auc=0.537\n",
      "Epoch 320 | val_loss=1.0460 acc=0.792 f1=0.038 auc=0.484\n",
      "Epoch 325 | val_loss=0.9033 acc=0.812 f1=0.118 auc=0.572\n",
      "Epoch 330 | val_loss=1.2380 acc=0.750 f1=0.032 auc=0.425\n",
      "Epoch 335 | val_loss=1.1333 acc=0.746 f1=0.062 auc=0.533\n",
      "Epoch 340 | val_loss=1.0965 acc=0.767 f1=0.067 auc=0.530\n",
      "Epoch 345 | val_loss=0.9462 acc=0.787 f1=0.038 auc=0.465\n",
      "Epoch 350 | val_loss=0.9581 acc=0.783 f1=0.071 auc=0.531\n",
      "Epoch 355 | val_loss=0.9398 acc=0.796 f1=0.039 auc=0.611\n",
      "Epoch 360 | val_loss=1.2444 acc=0.750 f1=0.091 auc=0.472\n",
      "Epoch 365 | val_loss=1.1650 acc=0.762 f1=0.123 auc=0.480\n",
      "Epoch 370 | val_loss=1.1920 acc=0.742 f1=0.061 auc=0.509\n",
      "Epoch 375 | val_loss=0.9728 acc=0.771 f1=0.068 auc=0.516\n",
      "Epoch 380 | val_loss=1.1313 acc=0.754 f1=0.000 auc=0.455\n",
      "Epoch 385 | val_loss=1.0646 acc=0.792 f1=0.038 auc=0.465\n",
      "Epoch 390 | val_loss=0.8926 acc=0.808 f1=0.000 auc=0.441\n",
      "Epoch 395 | val_loss=0.8956 acc=0.796 f1=0.039 auc=0.508\n",
      "Epoch 400 | val_loss=1.0808 acc=0.779 f1=0.000 auc=0.393\n",
      "Epoch 405 | val_loss=1.1833 acc=0.792 f1=0.038 auc=0.348\n",
      "Epoch 410 | val_loss=1.0679 acc=0.804 f1=0.041 auc=0.451\n",
      "Epoch 415 | val_loss=0.9755 acc=0.771 f1=0.098 auc=0.564\n",
      "Epoch 420 | val_loss=1.0422 acc=0.804 f1=0.113 auc=0.484\n",
      "Epoch 425 | val_loss=0.9331 acc=0.796 f1=0.075 auc=0.539\n",
      "Epoch 430 | val_loss=0.9285 acc=0.808 f1=0.115 auc=0.558\n",
      "Epoch 435 | val_loss=1.1746 acc=0.771 f1=0.068 auc=0.482\n",
      "Epoch 440 | val_loss=1.0317 acc=0.796 f1=0.039 auc=0.443\n",
      "Epoch 445 | val_loss=1.0323 acc=0.787 f1=0.105 auc=0.481\n",
      "Epoch 450 | val_loss=1.1169 acc=0.787 f1=0.038 auc=0.411\n",
      "Epoch 455 | val_loss=0.9872 acc=0.808 f1=0.000 auc=0.458\n",
      "Epoch 460 | val_loss=0.9615 acc=0.804 f1=0.041 auc=0.445\n",
      "Epoch 465 | val_loss=0.8293 acc=0.808 f1=0.042 auc=0.606\n",
      "Epoch 470 | val_loss=1.0045 acc=0.775 f1=0.069 auc=0.477\n",
      "Epoch 475 | val_loss=1.1137 acc=0.775 f1=0.129 auc=0.538\n",
      "Epoch 480 | val_loss=0.8206 acc=0.825 f1=0.045 auc=0.552\n",
      "Epoch 485 | val_loss=1.0855 acc=0.775 f1=0.036 auc=0.522\n",
      "Epoch 490 | val_loss=0.8972 acc=0.846 f1=0.000 auc=0.428\n",
      "Epoch 495 | val_loss=0.7367 acc=0.875 f1=0.000 auc=0.420\n",
      "Epoch 500 | val_loss=0.8398 acc=0.838 f1=0.133 auc=0.530\n",
      "Epoch 505 | val_loss=1.2581 acc=0.758 f1=0.000 auc=0.436\n",
      "Epoch 510 | val_loss=0.8823 acc=0.796 f1=0.000 auc=0.494\n",
      "Epoch 515 | val_loss=0.8083 acc=0.846 f1=0.140 auc=0.539\n",
      "Epoch 520 | val_loss=0.8294 acc=0.817 f1=0.000 auc=0.541\n",
      "Epoch 525 | val_loss=0.6736 acc=0.842 f1=0.136 auc=0.582\n",
      "Epoch 530 | val_loss=0.8129 acc=0.846 f1=0.178 auc=0.575\n",
      "Epoch 535 | val_loss=0.6973 acc=0.846 f1=0.140 auc=0.618\n",
      "Epoch 540 | val_loss=0.6906 acc=0.863 f1=0.000 auc=0.480\n",
      "Epoch 545 | val_loss=0.7683 acc=0.842 f1=0.136 auc=0.524\n",
      "Epoch 550 | val_loss=0.7580 acc=0.842 f1=0.136 auc=0.567\n",
      "Epoch 555 | val_loss=1.0750 acc=0.804 f1=0.041 auc=0.468\n",
      "Epoch 560 | val_loss=0.7899 acc=0.825 f1=0.087 auc=0.529\n",
      "Epoch 565 | val_loss=0.8608 acc=0.796 f1=0.039 auc=0.541\n",
      "Epoch 570 | val_loss=0.7299 acc=0.858 f1=0.000 auc=0.514\n",
      "Epoch 575 | val_loss=0.6960 acc=0.854 f1=0.103 auc=0.650\n",
      "Epoch 580 | val_loss=0.5503 acc=0.879 f1=0.171 auc=0.644\n",
      "Epoch 585 | val_loss=0.7175 acc=0.850 f1=0.143 auc=0.622\n",
      "Epoch 590 | val_loss=0.7537 acc=0.812 f1=0.082 auc=0.613\n",
      "Epoch 595 | val_loss=0.6916 acc=0.858 f1=0.056 auc=0.582\n",
      "Epoch 600 | val_loss=0.9197 acc=0.775 f1=0.036 auc=0.511\n",
      "Epoch 605 | val_loss=0.6834 acc=0.858 f1=0.105 auc=0.600\n",
      "Epoch 610 | val_loss=0.5726 acc=0.863 f1=0.108 auc=0.607\n",
      "Epoch 615 | val_loss=0.6234 acc=0.858 f1=0.056 auc=0.577\n",
      "Epoch 620 | val_loss=0.8174 acc=0.817 f1=0.043 auc=0.528\n",
      "Epoch 625 | val_loss=0.5952 acc=0.875 f1=0.000 auc=0.568\n",
      "Epoch 630 | val_loss=0.5066 acc=0.867 f1=0.059 auc=0.698\n",
      "Epoch 635 | val_loss=0.7018 acc=0.871 f1=0.162 auc=0.609\n",
      "Epoch 640 | val_loss=0.5972 acc=0.875 f1=0.000 auc=0.548\n",
      "Epoch 645 | val_loss=0.7862 acc=0.825 f1=0.087 auc=0.567\n",
      "Epoch 650 | val_loss=0.7013 acc=0.850 f1=0.143 auc=0.584\n",
      "Epoch 655 | val_loss=0.7664 acc=0.838 f1=0.093 auc=0.588\n",
      "Epoch 660 | val_loss=0.6447 acc=0.850 f1=0.182 auc=0.625\n",
      "Epoch 665 | val_loss=0.5865 acc=0.863 f1=0.057 auc=0.547\n",
      "Epoch 670 | val_loss=0.6562 acc=0.867 f1=0.059 auc=0.511\n",
      "Epoch 675 | val_loss=0.6265 acc=0.892 f1=0.071 auc=0.529\n",
      "Epoch 680 | val_loss=0.6992 acc=0.858 f1=0.056 auc=0.478\n",
      "Epoch 685 | val_loss=0.6519 acc=0.871 f1=0.114 auc=0.550\n",
      "Epoch 690 | val_loss=0.6666 acc=0.879 f1=0.065 auc=0.488\n",
      "Epoch 695 | val_loss=0.5242 acc=0.900 f1=0.200 auc=0.601\n",
      "Epoch 700 | val_loss=0.5670 acc=0.883 f1=0.067 auc=0.586\n",
      "Epoch 705 | val_loss=0.7013 acc=0.846 f1=0.098 auc=0.674\n",
      "Epoch 710 | val_loss=0.7296 acc=0.854 f1=0.054 auc=0.491\n",
      "Epoch 715 | val_loss=0.7790 acc=0.846 f1=0.098 auc=0.520\n",
      "Epoch 720 | val_loss=0.7623 acc=0.858 f1=0.056 auc=0.413\n",
      "Epoch 725 | val_loss=0.7012 acc=0.883 f1=0.125 auc=0.470\n",
      "Epoch 730 | val_loss=0.7551 acc=0.867 f1=0.111 auc=0.500\n",
      "Epoch 735 | val_loss=0.7117 acc=0.867 f1=0.000 auc=0.403\n",
      "Epoch 740 | val_loss=0.8097 acc=0.850 f1=0.100 auc=0.467\n",
      "Epoch 745 | val_loss=0.5713 acc=0.892 f1=0.071 auc=0.567\n",
      "Epoch 750 | val_loss=0.9109 acc=0.829 f1=0.047 auc=0.381\n",
      "Epoch 755 | val_loss=0.7405 acc=0.879 f1=0.000 auc=0.457\n",
      "Epoch 760 | val_loss=0.7157 acc=0.875 f1=0.062 auc=0.443\n",
      "Epoch 765 | val_loss=0.7293 acc=0.875 f1=0.118 auc=0.463\n",
      "Epoch 770 | val_loss=0.6475 acc=0.850 f1=0.000 auc=0.586\n",
      "Epoch 775 | val_loss=0.6186 acc=0.875 f1=0.118 auc=0.576\n",
      "Epoch 780 | val_loss=0.5581 acc=0.892 f1=0.071 auc=0.557\n",
      "Epoch 785 | val_loss=0.5842 acc=0.892 f1=0.188 auc=0.608\n",
      "Epoch 790 | val_loss=0.5434 acc=0.904 f1=0.148 auc=0.547\n",
      "Epoch 795 | val_loss=0.6884 acc=0.887 f1=0.129 auc=0.415\n",
      "Epoch 800 | val_loss=0.6191 acc=0.871 f1=0.061 auc=0.595\n",
      "Epoch 805 | val_loss=0.6572 acc=0.858 f1=0.105 auc=0.579\n",
      "Epoch 810 | val_loss=0.6080 acc=0.896 f1=0.000 auc=0.491\n",
      "Epoch 815 | val_loss=0.6300 acc=0.887 f1=0.069 auc=0.530\n",
      "Epoch 820 | val_loss=0.6231 acc=0.875 f1=0.062 auc=0.539\n",
      "Epoch 825 | val_loss=0.6679 acc=0.879 f1=0.065 auc=0.529\n",
      "Epoch 830 | val_loss=0.6088 acc=0.883 f1=0.067 auc=0.542\n",
      "Epoch 835 | val_loss=0.6548 acc=0.858 f1=0.105 auc=0.517\n",
      "Epoch 840 | val_loss=0.6411 acc=0.875 f1=0.167 auc=0.639\n",
      "Epoch 845 | val_loss=0.6453 acc=0.883 f1=0.125 auc=0.542\n",
      "Epoch 850 | val_loss=0.5594 acc=0.879 f1=0.000 auc=0.607\n",
      "Epoch 855 | val_loss=0.5337 acc=0.896 f1=0.074 auc=0.591\n",
      "Epoch 860 | val_loss=0.5700 acc=0.879 f1=0.121 auc=0.615\n",
      "Epoch 865 | val_loss=0.7135 acc=0.871 f1=0.000 auc=0.493\n",
      "Epoch 870 | val_loss=0.6433 acc=0.892 f1=0.133 auc=0.555\n",
      "Epoch 875 | val_loss=0.7286 acc=0.875 f1=0.062 auc=0.510\n",
      "Epoch 880 | val_loss=0.6725 acc=0.875 f1=0.118 auc=0.634\n",
      "Epoch 885 | val_loss=0.5702 acc=0.896 f1=0.000 auc=0.534\n",
      "Epoch 890 | val_loss=0.7338 acc=0.875 f1=0.118 auc=0.552\n",
      "Epoch 895 | val_loss=0.5085 acc=0.929 f1=0.190 auc=0.548\n",
      "Epoch 900 | val_loss=0.7204 acc=0.879 f1=0.171 auc=0.601\n",
      "Epoch 905 | val_loss=0.6046 acc=0.892 f1=0.188 auc=0.552\n",
      "Epoch 910 | val_loss=0.6108 acc=0.871 f1=0.114 auc=0.674\n",
      "Epoch 915 | val_loss=0.5082 acc=0.900 f1=0.077 auc=0.602\n",
      "Epoch 920 | val_loss=0.5265 acc=0.904 f1=0.148 auc=0.651\n",
      "Epoch 925 | val_loss=0.5571 acc=0.904 f1=0.000 auc=0.543\n",
      "Epoch 930 | val_loss=0.6130 acc=0.896 f1=0.074 auc=0.540\n",
      "Epoch 935 | val_loss=0.5132 acc=0.917 f1=0.167 auc=0.581\n",
      "Epoch 940 | val_loss=0.5331 acc=0.904 f1=0.148 auc=0.643\n",
      "Epoch 945 | val_loss=0.6566 acc=0.883 f1=0.067 auc=0.613\n",
      "Epoch 950 | val_loss=0.7973 acc=0.846 f1=0.051 auc=0.532\n",
      "Epoch 955 | val_loss=0.5545 acc=0.904 f1=0.080 auc=0.547\n",
      "Epoch 960 | val_loss=0.8428 acc=0.854 f1=0.103 auc=0.538\n",
      "Epoch 965 | val_loss=0.5462 acc=0.892 f1=0.133 auc=0.597\n",
      "Epoch 970 | val_loss=0.6977 acc=0.892 f1=0.071 auc=0.495\n",
      "Epoch 975 | val_loss=0.6908 acc=0.896 f1=0.138 auc=0.472\n",
      "Epoch 980 | val_loss=0.7688 acc=0.846 f1=0.051 auc=0.577\n",
      "Epoch 985 | val_loss=0.6004 acc=0.896 f1=0.242 auc=0.640\n",
      "Epoch 990 | val_loss=0.7046 acc=0.875 f1=0.167 auc=0.500\n",
      "Epoch 995 | val_loss=0.5606 acc=0.900 f1=0.000 auc=0.565\n",
      "Epoch 1000 | val_loss=0.6241 acc=0.887 f1=0.069 auc=0.567\n",
      "Epoch 1005 | val_loss=0.6157 acc=0.875 f1=0.000 auc=0.562\n",
      "Epoch 1010 | val_loss=0.7048 acc=0.908 f1=0.267 auc=0.485\n",
      "Epoch 1015 | val_loss=0.6011 acc=0.896 f1=0.074 auc=0.576\n",
      "Epoch 1020 | val_loss=0.5193 acc=0.908 f1=0.000 auc=0.603\n",
      "Epoch 1025 | val_loss=0.5741 acc=0.887 f1=0.069 auc=0.612\n",
      "Epoch 1030 | val_loss=0.5471 acc=0.912 f1=0.160 auc=0.552\n",
      "Epoch 1035 | val_loss=0.7090 acc=0.892 f1=0.133 auc=0.558\n",
      "Epoch 1040 | val_loss=0.5695 acc=0.896 f1=0.074 auc=0.581\n",
      "Epoch 1045 | val_loss=0.5693 acc=0.892 f1=0.235 auc=0.629\n",
      "Epoch 1050 | val_loss=0.7233 acc=0.879 f1=0.121 auc=0.517\n",
      "Epoch 1055 | val_loss=0.5624 acc=0.900 f1=0.077 auc=0.601\n",
      "Epoch 1060 | val_loss=0.7235 acc=0.892 f1=0.071 auc=0.465\n",
      "Epoch 1065 | val_loss=0.5587 acc=0.904 f1=0.207 auc=0.612\n",
      "Epoch 1070 | val_loss=0.6377 acc=0.892 f1=0.071 auc=0.508\n",
      "Epoch 1075 | val_loss=0.8058 acc=0.879 f1=0.000 auc=0.426\n",
      "Epoch 1080 | val_loss=0.7977 acc=0.887 f1=0.129 auc=0.429\n",
      "Epoch 1085 | val_loss=0.7635 acc=0.896 f1=0.074 auc=0.389\n",
      "Epoch 1090 | val_loss=0.5385 acc=0.912 f1=0.087 auc=0.572\n",
      "Epoch 1095 | val_loss=0.6669 acc=0.879 f1=0.121 auc=0.592\n",
      "Epoch 1100 | val_loss=0.6847 acc=0.896 f1=0.000 auc=0.495\n",
      "Epoch 1105 | val_loss=0.5411 acc=0.912 f1=0.087 auc=0.592\n",
      "Epoch 1110 | val_loss=0.6538 acc=0.904 f1=0.148 auc=0.529\n",
      "Epoch 1115 | val_loss=0.6516 acc=0.904 f1=0.148 auc=0.472\n",
      "Epoch 1120 | val_loss=0.6744 acc=0.871 f1=0.000 auc=0.497\n",
      "Epoch 1125 | val_loss=0.6328 acc=0.883 f1=0.125 auc=0.531\n",
      "Epoch 1130 | val_loss=0.6070 acc=0.908 f1=0.000 auc=0.496\n",
      "Epoch 1135 | val_loss=0.6516 acc=0.867 f1=0.111 auc=0.590\n",
      "Epoch 1140 | val_loss=0.5369 acc=0.908 f1=0.000 auc=0.541\n",
      "Epoch 1145 | val_loss=0.4947 acc=0.908 f1=0.083 auc=0.672\n",
      "Epoch 1150 | val_loss=0.5298 acc=0.921 f1=0.095 auc=0.573\n",
      "Epoch 1155 | val_loss=0.6156 acc=0.921 f1=0.095 auc=0.479\n",
      "Epoch 1160 | val_loss=0.6028 acc=0.917 f1=0.091 auc=0.428\n",
      "Epoch 1165 | val_loss=0.4613 acc=0.938 f1=0.000 auc=0.636\n",
      "Epoch 1170 | val_loss=0.5702 acc=0.896 f1=0.074 auc=0.634\n",
      "Epoch 1175 | val_loss=0.5705 acc=0.896 f1=0.000 auc=0.585\n",
      "Epoch 1180 | val_loss=0.5341 acc=0.912 f1=0.000 auc=0.536\n",
      "Epoch 1185 | val_loss=0.5022 acc=0.912 f1=0.000 auc=0.665\n",
      "Epoch 1190 | val_loss=0.5231 acc=0.917 f1=0.000 auc=0.551\n",
      "Epoch 1195 | val_loss=0.5731 acc=0.900 f1=0.143 auc=0.611\n",
      "Epoch 1200 | val_loss=0.5610 acc=0.933 f1=0.200 auc=0.519\n",
      "Epoch 1205 | val_loss=0.5321 acc=0.917 f1=0.091 auc=0.588\n",
      "Epoch 1210 | val_loss=0.5652 acc=0.896 f1=0.138 auc=0.555\n",
      "Epoch 1215 | val_loss=0.7603 acc=0.900 f1=0.143 auc=0.506\n",
      "Epoch 1220 | val_loss=0.5856 acc=0.925 f1=0.100 auc=0.460\n",
      "Epoch 1225 | val_loss=0.4687 acc=0.904 f1=0.207 auc=0.707\n",
      "Epoch 1230 | val_loss=0.7426 acc=0.883 f1=0.000 auc=0.481\n",
      "Epoch 1235 | val_loss=0.6055 acc=0.912 f1=0.276 auc=0.679\n",
      "Epoch 1240 | val_loss=0.6129 acc=0.896 f1=0.074 auc=0.588\n",
      "Epoch 1245 | val_loss=0.5977 acc=0.887 f1=0.129 auc=0.669\n",
      "Epoch 1250 | val_loss=0.4375 acc=0.929 f1=0.105 auc=0.645\n",
      "Epoch 1255 | val_loss=0.6068 acc=0.925 f1=0.182 auc=0.526\n",
      "Epoch 1260 | val_loss=0.5951 acc=0.900 f1=0.077 auc=0.579\n",
      "Epoch 1265 | val_loss=0.5382 acc=0.929 f1=0.000 auc=0.491\n",
      "Epoch 1270 | val_loss=0.5949 acc=0.896 f1=0.000 auc=0.545\n",
      "Epoch 1275 | val_loss=0.6000 acc=0.912 f1=0.087 auc=0.482\n",
      "Epoch 1280 | val_loss=0.5059 acc=0.912 f1=0.087 auc=0.623\n",
      "Epoch 1285 | val_loss=0.4052 acc=0.925 f1=0.182 auc=0.702\n",
      "Epoch 1290 | val_loss=0.5613 acc=0.896 f1=0.074 auc=0.578\n",
      "Epoch 1295 | val_loss=0.6146 acc=0.908 f1=0.000 auc=0.552\n",
      "Epoch 1300 | val_loss=0.6335 acc=0.908 f1=0.000 auc=0.490\n",
      "Epoch 1305 | val_loss=0.7551 acc=0.871 f1=0.000 auc=0.541\n",
      "Epoch 1310 | val_loss=0.6060 acc=0.900 f1=0.000 auc=0.549\n",
      "Epoch 1315 | val_loss=0.5728 acc=0.912 f1=0.000 auc=0.584\n",
      "Epoch 1320 | val_loss=0.7337 acc=0.900 f1=0.000 auc=0.432\n",
      "Epoch 1325 | val_loss=0.5327 acc=0.921 f1=0.095 auc=0.569\n",
      "Epoch 1330 | val_loss=0.6259 acc=0.912 f1=0.087 auc=0.457\n",
      "Epoch 1335 | val_loss=0.4779 acc=0.921 f1=0.174 auc=0.634\n",
      "Epoch 1340 | val_loss=0.5047 acc=0.912 f1=0.160 auc=0.607\n",
      "Epoch 1345 | val_loss=0.6506 acc=0.908 f1=0.000 auc=0.448\n",
      "Epoch 1350 | val_loss=0.6341 acc=0.917 f1=0.000 auc=0.440\n",
      "Epoch 1355 | val_loss=0.5454 acc=0.892 f1=0.000 auc=0.674\n",
      "Epoch 1360 | val_loss=0.5518 acc=0.908 f1=0.000 auc=0.546\n",
      "Epoch 1365 | val_loss=0.6762 acc=0.912 f1=0.160 auc=0.522\n",
      "Epoch 1370 | val_loss=0.5827 acc=0.929 f1=0.190 auc=0.484\n",
      "Epoch 1375 | val_loss=0.7461 acc=0.917 f1=0.000 auc=0.395\n",
      "Epoch 1380 | val_loss=0.6858 acc=0.908 f1=0.083 auc=0.486\n",
      "Epoch 1385 | val_loss=0.6889 acc=0.921 f1=0.000 auc=0.424\n",
      "Epoch 1390 | val_loss=0.5468 acc=0.929 f1=0.000 auc=0.565\n",
      "Epoch 1395 | val_loss=0.6446 acc=0.912 f1=0.087 auc=0.486\n",
      "Epoch 1400 | val_loss=0.6474 acc=0.912 f1=0.000 auc=0.466\n",
      "Epoch 1405 | val_loss=0.6147 acc=0.929 f1=0.000 auc=0.491\n",
      "Epoch 1410 | val_loss=0.6511 acc=0.917 f1=0.000 auc=0.476\n",
      "Epoch 1415 | val_loss=0.6262 acc=0.892 f1=0.000 auc=0.562\n",
      "Epoch 1420 | val_loss=0.6859 acc=0.892 f1=0.000 auc=0.540\n",
      "Epoch 1425 | val_loss=0.6299 acc=0.904 f1=0.080 auc=0.565\n",
      "Epoch 1430 | val_loss=0.5085 acc=0.904 f1=0.000 auc=0.632\n",
      "Epoch 1435 | val_loss=0.4896 acc=0.929 f1=0.190 auc=0.637\n",
      "Epoch 1440 | val_loss=0.5123 acc=0.912 f1=0.000 auc=0.624\n",
      "Epoch 1445 | val_loss=0.6623 acc=0.908 f1=0.000 auc=0.534\n",
      "Epoch 1450 | val_loss=0.6971 acc=0.904 f1=0.000 auc=0.467\n",
      "Epoch 1455 | val_loss=0.6221 acc=0.917 f1=0.091 auc=0.497\n",
      "Epoch 1460 | val_loss=0.5874 acc=0.900 f1=0.077 auc=0.536\n",
      "Epoch 1465 | val_loss=0.5441 acc=0.908 f1=0.000 auc=0.591\n",
      "Epoch 1470 | val_loss=0.5889 acc=0.896 f1=0.138 auc=0.652\n",
      "Epoch 1475 | val_loss=0.5924 acc=0.904 f1=0.207 auc=0.639\n",
      "Epoch 1480 | val_loss=0.4961 acc=0.921 f1=0.000 auc=0.631\n",
      "Epoch 1485 | val_loss=0.6459 acc=0.908 f1=0.083 auc=0.521\n",
      "Epoch 1490 | val_loss=0.4987 acc=0.925 f1=0.100 auc=0.619\n",
      "Epoch 1495 | val_loss=0.7663 acc=0.892 f1=0.000 auc=0.492\n",
      "Epoch 1500 | val_loss=0.4948 acc=0.925 f1=0.100 auc=0.637\n",
      "Epoch 1505 | val_loss=0.5893 acc=0.921 f1=0.000 auc=0.513\n",
      "Epoch 1510 | val_loss=0.6388 acc=0.925 f1=0.100 auc=0.453\n",
      "Epoch 1515 | val_loss=0.8632 acc=0.904 f1=0.000 auc=0.378\n",
      "Epoch 1520 | val_loss=0.5808 acc=0.921 f1=0.095 auc=0.533\n",
      "Epoch 1525 | val_loss=0.5880 acc=0.921 f1=0.095 auc=0.531\n",
      "Epoch 1530 | val_loss=0.5411 acc=0.917 f1=0.000 auc=0.576\n",
      "Epoch 1535 | val_loss=0.6865 acc=0.908 f1=0.000 auc=0.484\n",
      "Epoch 1540 | val_loss=0.6788 acc=0.912 f1=0.087 auc=0.463\n",
      "Epoch 1545 | val_loss=0.5172 acc=0.933 f1=0.000 auc=0.550\n",
      "Epoch 1550 | val_loss=0.7026 acc=0.887 f1=0.069 auc=0.473\n",
      "Epoch 1555 | val_loss=0.5944 acc=0.912 f1=0.000 auc=0.570\n",
      "Epoch 1560 | val_loss=0.5793 acc=0.900 f1=0.000 auc=0.640\n",
      "Epoch 1565 | val_loss=0.5418 acc=0.942 f1=0.222 auc=0.521\n",
      "Epoch 1570 | val_loss=0.5256 acc=0.917 f1=0.091 auc=0.670\n",
      "Epoch 1575 | val_loss=0.7420 acc=0.875 f1=0.000 auc=0.463\n",
      "Epoch 1580 | val_loss=0.5452 acc=0.908 f1=0.214 auc=0.649\n",
      "Epoch 1585 | val_loss=0.7550 acc=0.904 f1=0.080 auc=0.466\n",
      "Epoch 1590 | val_loss=0.4632 acc=0.929 f1=0.000 auc=0.638\n",
      "Epoch 1595 | val_loss=0.5957 acc=0.933 f1=0.200 auc=0.578\n",
      "Epoch 1600 | val_loss=0.6851 acc=0.938 f1=0.118 auc=0.430\n",
      "Epoch 1605 | val_loss=0.4898 acc=0.908 f1=0.083 auc=0.644\n",
      "Epoch 1610 | val_loss=0.5689 acc=0.929 f1=0.105 auc=0.600\n",
      "Epoch 1615 | val_loss=0.6444 acc=0.921 f1=0.000 auc=0.479\n",
      "Epoch 1620 | val_loss=0.4920 acc=0.912 f1=0.160 auc=0.691\n",
      "Epoch 1625 | val_loss=0.5531 acc=0.925 f1=0.182 auc=0.598\n",
      "Epoch 1630 | val_loss=0.6018 acc=0.900 f1=0.077 auc=0.682\n",
      "Epoch 1635 | val_loss=0.5097 acc=0.917 f1=0.091 auc=0.657\n",
      "Epoch 1640 | val_loss=0.6440 acc=0.925 f1=0.100 auc=0.463\n",
      "Epoch 1645 | val_loss=0.6080 acc=0.921 f1=0.000 auc=0.551\n",
      "Epoch 1650 | val_loss=0.5888 acc=0.925 f1=0.000 auc=0.569\n",
      "Epoch 1655 | val_loss=0.5957 acc=0.904 f1=0.148 auc=0.625\n",
      "Epoch 1660 | val_loss=0.4250 acc=0.929 f1=0.105 auc=0.677\n",
      "Epoch 1665 | val_loss=0.5445 acc=0.925 f1=0.182 auc=0.621\n",
      "Epoch 1670 | val_loss=0.6747 acc=0.917 f1=0.091 auc=0.493\n",
      "Epoch 1675 | val_loss=0.7075 acc=0.892 f1=0.000 auc=0.511\n",
      "Epoch 1680 | val_loss=0.5986 acc=0.925 f1=0.100 auc=0.559\n",
      "Epoch 1685 | val_loss=0.5422 acc=0.929 f1=0.000 auc=0.587\n",
      "Epoch 1690 | val_loss=0.6351 acc=0.908 f1=0.083 auc=0.519\n",
      "Epoch 1695 | val_loss=0.6290 acc=0.908 f1=0.000 auc=0.514\n",
      "Epoch 1700 | val_loss=0.6225 acc=0.896 f1=0.194 auc=0.647\n",
      "Epoch 1705 | val_loss=0.7383 acc=0.912 f1=0.000 auc=0.492\n",
      "Epoch 1710 | val_loss=0.5988 acc=0.921 f1=0.000 auc=0.556\n",
      "Epoch 1715 | val_loss=0.7289 acc=0.912 f1=0.087 auc=0.393\n",
      "Epoch 1720 | val_loss=0.5093 acc=0.942 f1=0.000 auc=0.601\n",
      "Epoch 1725 | val_loss=0.4658 acc=0.921 f1=0.000 auc=0.653\n",
      "Epoch 1730 | val_loss=0.4880 acc=0.929 f1=0.105 auc=0.622\n",
      "Epoch 1735 | val_loss=0.5763 acc=0.942 f1=0.000 auc=0.532\n",
      "Epoch 1740 | val_loss=0.5988 acc=0.912 f1=0.160 auc=0.528\n",
      "Epoch 1745 | val_loss=0.4627 acc=0.942 f1=0.125 auc=0.665\n",
      "Epoch 1750 | val_loss=0.5865 acc=0.938 f1=0.000 auc=0.515\n",
      "Epoch 1755 | val_loss=0.6868 acc=0.912 f1=0.000 auc=0.464\n",
      "Epoch 1760 | val_loss=0.8657 acc=0.867 f1=0.000 auc=0.347\n",
      "Epoch 1765 | val_loss=0.6064 acc=0.929 f1=0.000 auc=0.533\n",
      "Epoch 1770 | val_loss=0.6854 acc=0.938 f1=0.000 auc=0.443\n",
      "Epoch 1775 | val_loss=0.6864 acc=0.900 f1=0.077 auc=0.583\n",
      "Epoch 1780 | val_loss=0.6386 acc=0.875 f1=0.062 auc=0.560\n",
      "Epoch 1785 | val_loss=0.7146 acc=0.921 f1=0.000 auc=0.430\n",
      "Epoch 1790 | val_loss=0.4377 acc=0.925 f1=0.100 auc=0.711\n",
      "Epoch 1795 | val_loss=0.6948 acc=0.912 f1=0.000 auc=0.464\n",
      "Epoch 1800 | val_loss=0.4682 acc=0.925 f1=0.100 auc=0.668\n",
      "Epoch 1805 | val_loss=0.7129 acc=0.908 f1=0.000 auc=0.468\n",
      "Epoch 1810 | val_loss=0.7752 acc=0.883 f1=0.125 auc=0.559\n",
      "Epoch 1815 | val_loss=0.7313 acc=0.925 f1=0.000 auc=0.408\n",
      "Epoch 1820 | val_loss=0.5409 acc=0.925 f1=0.100 auc=0.565\n",
      "Epoch 1825 | val_loss=0.6993 acc=0.929 f1=0.190 auc=0.383\n",
      "Epoch 1830 | val_loss=0.5770 acc=0.908 f1=0.083 auc=0.625\n",
      "Epoch 1835 | val_loss=0.7288 acc=0.900 f1=0.000 auc=0.495\n",
      "Epoch 1840 | val_loss=0.6369 acc=0.925 f1=0.000 auc=0.503\n",
      "Epoch 1845 | val_loss=0.6953 acc=0.912 f1=0.087 auc=0.474\n",
      "Epoch 1850 | val_loss=0.6397 acc=0.912 f1=0.000 auc=0.493\n",
      "Epoch 1855 | val_loss=0.5522 acc=0.929 f1=0.000 auc=0.613\n",
      "Epoch 1860 | val_loss=0.5706 acc=0.929 f1=0.000 auc=0.530\n",
      "Epoch 1865 | val_loss=0.6369 acc=0.933 f1=0.111 auc=0.531\n",
      "Epoch 1870 | val_loss=0.6996 acc=0.904 f1=0.080 auc=0.449\n",
      "Epoch 1875 | val_loss=0.4874 acc=0.925 f1=0.100 auc=0.660\n",
      "Epoch 1880 | val_loss=0.6379 acc=0.921 f1=0.095 auc=0.471\n",
      "Epoch 1885 | val_loss=0.7037 acc=0.908 f1=0.000 auc=0.444\n",
      "Epoch 1890 | val_loss=0.6980 acc=0.900 f1=0.077 auc=0.448\n",
      "Epoch 1895 | val_loss=0.6559 acc=0.933 f1=0.111 auc=0.481\n",
      "Epoch 1900 | val_loss=0.8688 acc=0.904 f1=0.000 auc=0.364\n",
      "Epoch 1905 | val_loss=0.5327 acc=0.946 f1=0.133 auc=0.547\n",
      "Epoch 1910 | val_loss=0.5454 acc=0.938 f1=0.000 auc=0.569\n",
      "Epoch 1915 | val_loss=0.6489 acc=0.892 f1=0.000 auc=0.590\n",
      "Epoch 1920 | val_loss=0.6046 acc=0.938 f1=0.000 auc=0.497\n",
      "Epoch 1925 | val_loss=0.7044 acc=0.933 f1=0.111 auc=0.455\n",
      "Epoch 1930 | val_loss=0.5774 acc=0.942 f1=0.125 auc=0.546\n",
      "Epoch 1935 | val_loss=0.5464 acc=0.925 f1=0.000 auc=0.625\n",
      "Epoch 1940 | val_loss=0.6320 acc=0.933 f1=0.000 auc=0.477\n",
      "Epoch 1945 | val_loss=0.6116 acc=0.933 f1=0.000 auc=0.606\n",
      "Epoch 1950 | val_loss=0.6801 acc=0.929 f1=0.000 auc=0.435\n",
      "Epoch 1955 | val_loss=0.6055 acc=0.938 f1=0.000 auc=0.524\n",
      "Epoch 1960 | val_loss=0.7601 acc=0.879 f1=0.000 auc=0.466\n",
      "Epoch 1965 | val_loss=0.6068 acc=0.925 f1=0.100 auc=0.532\n",
      "Epoch 1970 | val_loss=0.6820 acc=0.942 f1=0.000 auc=0.406\n",
      "Epoch 1975 | val_loss=1.0293 acc=0.858 f1=0.000 auc=0.357\n",
      "Epoch 1980 | val_loss=0.6244 acc=0.900 f1=0.000 auc=0.537\n",
      "Epoch 1985 | val_loss=0.6476 acc=0.933 f1=0.000 auc=0.505\n",
      "Epoch 1990 | val_loss=0.6393 acc=0.887 f1=0.129 auc=0.544\n",
      "Epoch 1995 | val_loss=0.6790 acc=0.921 f1=0.000 auc=0.467\n",
      "Epoch 2000 | val_loss=0.6051 acc=0.917 f1=0.000 auc=0.592\n",
      "Epoch 2005 | val_loss=0.6105 acc=0.929 f1=0.000 auc=0.531\n",
      "Epoch 2010 | val_loss=0.6828 acc=0.900 f1=0.077 auc=0.511\n",
      "Epoch 2015 | val_loss=0.6241 acc=0.925 f1=0.000 auc=0.496\n",
      "Epoch 2020 | val_loss=0.6025 acc=0.933 f1=0.111 auc=0.493\n",
      "Epoch 2025 | val_loss=0.6430 acc=0.912 f1=0.087 auc=0.539\n",
      "Epoch 2030 | val_loss=0.7829 acc=0.917 f1=0.091 auc=0.386\n",
      "Epoch 2035 | val_loss=0.3945 acc=0.942 f1=0.125 auc=0.673\n",
      "Best @ epoch 2036 val_loss 0.3341 acc 0.942\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best = {\"epoch\":-1, \"loss\":1e9, \"acc\":0, \"state\":None}\n",
    "EPOCHS = 2036\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        opt.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        # Clip to stabilize STE\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "    val_loss, acc, f1, auc = evaluate()\n",
    "    if val_loss < best[\"loss\"]:\n",
    "        best.update({\"epoch\":epoch, \"loss\":val_loss, \"acc\":acc, \"state\":model.state_dict()})\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:02d} | val_loss={val_loss:.4f} acc={acc:.3f} f1={f1:.3f} auc={auc:.3f}\")\n",
    "\n",
    "# Load best\n",
    "model.load_state_dict(best[\"state\"])\n",
    "print(\"Best @ epoch\", best[\"epoch\"], \"val_loss\", round(best[\"loss\"],4), \"acc\", round(best[\"acc\"],3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e18fe4",
   "metadata": {},
   "source": [
    "## 5) Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c358cd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9534    0.9868    0.9698       228\n",
      "           1     0.2500    0.0833    0.1250        12\n",
      "\n",
      "    accuracy                         0.9417       240\n",
      "   macro avg     0.6017    0.5351    0.5474       240\n",
      "weighted avg     0.9182    0.9417    0.9276       240\n",
      "\n",
      "ROC-AUC: 0.7280701754385965\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(torch.from_numpy(X_test).to(device)).cpu().numpy()\n",
    "y_prob = 1/(1+np.exp(-logits))\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure()\n",
    "plt.imshow(cm, interpolation='nearest', aspect='auto')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, ['No Asthma','Asthma'])\n",
    "plt.yticks(tick_marks, ['No Asthma','Asthma'])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center')\n",
    "plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa9e999",
   "metadata": {},
   "source": [
    "## 6) Inference Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eac8dcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asthma_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.447602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Asthma_Prob\n",
       "0     0.000005\n",
       "1     0.447602\n",
       "2     0.002004\n",
       "3     0.000037\n",
       "4     0.014624"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict_proba(batch_df: pd.DataFrame):\n",
    "    # Apply the exact same cleaning pipeline\n",
    "    tmp = batch_df.copy()\n",
    "    # drop columns not in training predictors/target\n",
    "    keep = predictors + [target_col]\n",
    "    drop_extra = [c for c in tmp.columns if c not in keep]\n",
    "    tmp = tmp.drop(columns=drop_extra, errors='ignore')\n",
    "    # ensure columns order and presence\n",
    "    for c in predictors:\n",
    "        if c not in tmp.columns:\n",
    "            tmp[c] = 0.0\n",
    "    Xn = tmp[predictors].astype(np.float32).values\n",
    "    Xn = (Xn - x_mean) / (x_scale + 1e-8)\n",
    "    with torch.no_grad():\n",
    "        logits = model(torch.from_numpy(Xn).to(device)).cpu().numpy()\n",
    "    probs = 1/(1+np.exp(-logits))\n",
    "    return probs\n",
    "\n",
    "# Demo on first 5 rows\n",
    "sample = df.iloc[:5].copy()\n",
    "probs = predict_proba(sample)\n",
    "pd.DataFrame({'Asthma_Prob': probs})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ed1cb",
   "metadata": {},
   "source": [
    "## 7) Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "611d61b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to \\mnt\\data\\bnn_artifacts\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out_dir = Path('/mnt/data/bnn_artifacts')\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "torch.save(model.state_dict(), out_dir/'bnn_state.pt')\n",
    "with open(out_dir/'scaler.json','w') as f:\n",
    "    json.dump({'mean': x_mean.tolist(), 'scale': x_scale.tolist(), 'predictors': predictors, 'target': target_col}, f)\n",
    "print(\"Saved to\", out_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
